{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ntrain = pd.read_csv('../input/competitive-data-science-predict-future-sales/sales_train.csv')\n\n# Summing sales for each month and clipping\ntrain = train.groupby(['shop_id', 'item_id','date_block_num'])['item_cnt_day'].sum()\ntrain = train.reset_index()\ntrain['item_cnt_day'] = train['item_cnt_day'].map(lambda x: min(20, x)) \n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# Making flag is it is the first(release) month for (shop_id, item_id)\nfirst_month = train.groupby(['shop_id', 'item_id'])['date_block_num'].min()\ntrain['new_item'] = train.apply(lambda x: x['date_block_num'] == first_month[(x['shop_id'], x['item_id'])], axis='columns')\n\n\n# Add month, year\ntrain['month'] = train['date_block_num'].map(lambda x: (x % 12) + 1)\ntrain['year'] = train['date_block_num'].map(lambda x: 2013 + x // 12)\n\n\n# Add prev month sales for (shop_id, item_id)\nshop_item_db = train.groupby(['shop_id', 'item_id', 'date_block_num'])['item_cnt_day'].mean()\n\ndef make_prev_month_sales(x):\n    if (x['shop_id'], x['item_id'], x['date_block_num'] - 1) in shop_item_db.index:\n        return shop_item_db[(x['shop_id'], x['item_id'], x['date_block_num'] - 1)]\n    else:\n        return 0\n\ntrain['prev_month_sales'] = train.apply(make_prev_month_sales, axis='columns')\n\n\n# Add item category id\nitems = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\ntrain['cat_id'] = train['item_id'].map(lambda x: items.loc[x, 'item_category_id'])\n\n\n# Shop categories by location\ndef make_shop_loc(x):\n    # Yakutsk\n    if x in [0, 1, 57, 58]: \n        return 'Yakutsk 4'\n    # Moscow area\n    elif x in [3, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 54]:\n        return 'Moscow 16'\n    # Voronej\n    elif x in [6, 7, 8]:\n        return 'Voronej 3'\n    # Online\n    elif x in [9, 12, 55]:\n        return 'Online 3'\n    # Jukovski\n    elif x in [10, 11]:\n        return 'Jukovski 2'\n    # Kazan\n    elif x in [13, 14]:\n        return 'Kazan 2'\n    # Krasnoyarsk\n    elif x in [17, 18]:\n        return 'Krasnoyarsk 2'\n    # NNovgorod\n    elif x in [35, 36]:\n        return 'NNovgorod 2'\n    # Novosib\n    elif x in [36, 37]:\n        return 'Novosib 2'\n    # Rostov\n    elif x in [39, 40, 41]:\n        return 'Rostov 2'\n    # Spb\n    elif x in [42, 43]:\n        return 'Spb 2'\n    # Samara\n    elif x in [44, 45]:\n        return 'Samara 2'\n    # Tumen\n    elif x in [49, 50, 51]:\n        return 'Tumen 2'\n    # Ufa\n    elif x in [52, 53]:\n        return 'Ufa 2'\n    else:\n        return 'no_group'\n    \ntrain['shop_loc'] = train['shop_id'].map(make_shop_loc)\n\n\n# Adding flag if shop could not be meaningfully grouped\ntrain['no_loc_group'] = (train['shop_loc'] == 'no_group')\n\n\n# adding seasons\ndef make_season(x):\n    if x in [6, 7, 8]:\n        return 'summer'\n    elif x in [9, 10, 11]:\n        return 'autumn'\n    elif x in [3, 4, 5]:\n        return 'spring'\n    else:\n        return 'winter'\n\ntrain['season'] = train['month'].map(make_season)\n\n\n# seasonal sales for (shop_id, item_id)\nseasonal_sales = train.groupby(['shop_id', 'item_id', 'season'])['item_cnt_day'].sum()\n\ndef make_seasonal_sales(x):\n    if (x['shop_id'], x['item_id'], x['season']) in seasonal_sales.index:\n        return seasonal_sales[(x['shop_id'], x['item_id'], x['season'])] / 9\n    else:\n        return 0\n    \ntrain['seasonal_sales_shop_id'] = train.apply(make_seasonal_sales, axis='columns')\n\n\n# add prev month sales for (shop_loc, item_id)\nloc_item_db = train.groupby(['shop_loc', 'item_id', 'date_block_num'])['item_cnt_day'].mean()\n\ndef make_prev_month_sales_loc(x):\n    if x['shop_loc'] == 'no_group':\n        return x['prev_month_sales']\n    elif (x['shop_loc'], x['item_id'], x['date_block_num'] - 1) in loc_item_db.index:\n        num = x['shop_loc'].split()\n        num = int(num[1])\n        return loc_item_db[(x['shop_loc'], x['item_id'], x['date_block_num'] - 1)] / num\n    else:\n        return 0\n\ntrain['prev_month_sales_loc'] = train.apply(make_prev_month_sales_loc, axis='columns')\n\n\n# add seasonal sales for (shop_loc, item_id)\nloc_item_seasonal = train.groupby(['shop_loc', 'item_id', 'season'])['item_cnt_day'].sum()\n\ndef make_loc_item_seasonal(x):\n    if x['shop_loc'] == 'no_group':\n        return x['seasonal_sales_shop_id']\n    if (x['shop_loc'], x['item_id'], x['season']) in loc_item_seasonal.index:\n        num = x['shop_loc'].split()\n        num = int(num[1])\n        return loc_item_seasonal[(x['shop_loc'], x['item_id'], x['season'])] / num\n    else:\n        return 0\n\ntrain['loc_item_seasonal'] = train.apply(make_prev_month_sales, axis='columns')\n\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dec data is misleading, also for Jan prev_month_sales feature would be misleading.\n# So let's just drop Dec and Jan data. Since Feb is the only winter month left, let us drop it as well. xD\n\ntrain = train[(train['month'] != 1) & (train['month'] != 12) & (train['month'] != 2)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['shop_id',\n            'item_id',\n            'new_item',\n            'month',\n            'year',\n            'prev_month_sales',\n            'cat_id',\n            'shop_loc',\n            'no_loc_group',\n            'season', \n            'seasonal_sales_shop_id',\n            'prev_month_sales_loc',\n            'loc_item_seasonal',\n           ]\n\ncats = ['shop_id',\n        'item_id', \n        'new_item',\n        'month',\n        'year',\n        'cat_id',\n        'shop_loc',\n        'no_loc_group', \n        'season', \n        ]\n\nX = train[features]\ny = train['item_cnt_day']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PARAMETERS NOT OPTIMAL(I haven't done grid search yet.)\n# Also random train / val split doesn't make sense here, but whatever(going to improve that later).\n# The idea is to keep it fitting until eval score stops decreasing, but I was too lazy to wait.\n# At 3000 estimators eval score for this was ~0.95\n\nfrom sklearn.model_selection import train_test_split\nfrom catboost import CatBoostRegressor\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size= 0.2, random_state=1)\n\nmodel_ctb = CatBoostRegressor(iterations=10000,\n                              loss_function='RMSE',\n                              learning_rate=0.06,\n                              depth=8,\n                              l2_leaf_reg=11,\n                              random_seed=17,\n                              silent=True,\n                              eval_metric='RMSE',\n                              )\n\nmodel_ctb.fit(X_train, y_train,\n              cat_features=cats,\n              plot=True,\n              eval_set=(X_val, y_val),\n              )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transforming test data the same way.\n\ntest = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\n\ntest['date_block_num'] = 34 \ntest['new_item'] = test.apply(lambda x: not ((x['shop_id'], x['item_id']) in first_month.index), axis='columns')\ntest['month'] = 11\ntest['year'] = 2015\ntest['prev_month_sales'] = test.apply(make_prev_month_sales, axis='columns')\ntest['cat_id'] = test['item_id'].map(lambda x: items.loc[x, 'item_category_id'])\ntest['shop_loc'] = test['shop_id'].map(make_shop_loc)\ntest['no_loc_group'] = (test['shop_loc'] == 'no_group')\ntest['season'] = test['month'].map(make_season)\ntest['seasonal_sales_shop_id'] = test.apply(make_seasonal_sales, axis='columns')\ntest['prev_month_sales_loc'] = test.apply(make_prev_month_sales_loc, axis='columns')\ntest['loc_item_seasonal'] = test.apply(make_prev_month_sales, axis='columns')\n\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting the model on full training data using optimal number of iterations(which is not found yet, 3000 is basically a random guess).\n\nX = train[features]\ny = train['item_cnt_day']\n\nmodel_ctb = CatBoostRegressor(iterations=3000, loss_function='RMSE',\n                              learning_rate=0.06,\n                              depth=8,\n                              l2_leaf_reg=11,\n                              random_seed=17,\n                              silent=True,\n                              )\n\nmodel_ctb.fit(X, y,\n              cat_features=cats,\n              plot=True,\n              )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model_ctb.predict(test[features])\npredictions = pd.Series(predictions)\n\n\n# Clipping predictions into [0, 20]. Surprisingly, but some of them were negative... \npredictions = predictions.map(lambda x: max(0, min(20, x)))\n\ntest['pred'] = predictions\noutput = test[['ID', 'pred']]\noutput.columns = ['ID', 'item_cnt_month']\noutput = output.set_index('ID')\noutput.to_csv('catboost_baseline')\n\noutput.head()\n\n# lb score --->  1.156\n# Only slightly better than \"basic averages\" model... ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}